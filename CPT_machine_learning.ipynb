{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting files and pathways for model \n",
    "#config def at the bottom cell \n",
    "interesting_files = glob.glob(\"./training/*.csv\") \n",
    "df = pd.concat((pd.read_csv(f, header = 0) for f in interesting_files))\n",
    "df_deduplicated = df.drop_duplicates()\n",
    "df_deduplicated.to_csv(\"./train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(config):\n",
    "    df = pd.read_csv(config['train_path'])\n",
    "    df = df.fillna(0)\n",
    "    features = config['feature_names']\n",
    "    targets = config['label_name']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        df[features], df[targets], test_size=config['test_size'], random_state=42)\n",
    "    data_snapshot = {'x': X_train,\n",
    "                     'y': y_train,\n",
    "                     'xtest': X_test,\n",
    "                     'ytest': y_test,\n",
    "                     'features': features}\n",
    "\n",
    "    return data_snapshot\n",
    "\n",
    "\n",
    "def get_test_samples(config):\n",
    "    features = config['feature_names']\n",
    "    targets = config['label_name']\n",
    "    test_samples = []\n",
    "    test_path = config['test_path']\n",
    "    for file_name in os.listdir(test_path):\n",
    "        df = pd.read_csv(os.path.join(test_path, file_name))\n",
    "        z = df[config['depth_name']].fillna(0)\n",
    "        x = df[features].fillna(0)\n",
    "        y = df[targets].fillna(0)\n",
    "        test_samples.append((file_name, z, x, y))\n",
    "    return test_samples\n",
    "\n",
    "\n",
    "def train_rf(data, param):\n",
    "    clf = RandomForestClassifier(**param)  # hyperparameters for RFC\n",
    "    clf.fit(data['x'], data['y'])\n",
    "    print('Importance of Features:')\n",
    "    for feature, importance in zip(data['features'], clf.feature_importances_):\n",
    "        print('{}: {}'.format(feature, importance))\n",
    "\n",
    "    y_pred = clf.predict(data['xtest'])\n",
    "    print(classification_report(data['ytest'], y_pred))\n",
    "    return clf\n",
    "\n",
    "\n",
    "def train_mlp(data, param):\n",
    "    clf = MLPClassifier(**param)  # hyperparameters for RFC\n",
    "    clf.fit(data['x'], data['y'])\n",
    "    y_pred = clf.predict(data['xtest'])\n",
    "    print(classification_report(data['ytest'], y_pred))\n",
    "    return clf\n",
    "\n",
    "\n",
    "def smooth(series, w=3):\n",
    "    def smooth_one(i, j, k):\n",
    "        '''\n",
    "        check the mode of the w data in front and 2 data after\n",
    "        if the before-mode and the after-mode is the same\n",
    "        the current data will be replaced by the mode value\n",
    "        otherwise, no change\n",
    "        '''\n",
    "        mode1 = max(set(series[j:i]), key=series[j:i].count)\n",
    "        mode2 = max(set(series[i+1:k]), key=series[i+1:k].count)\n",
    "        if mode1 == mode2 and mode1 != series[i]:\n",
    "            return mode1\n",
    "        else:\n",
    "            return series[i]\n",
    "    for idx in range(w, len(series)-w):\n",
    "        series[idx] = smooth_one(idx, idx-w, idx+w+1)\n",
    "    return series\n",
    "\n",
    "\n",
    "def plot(clf, config, test_sample):\n",
    "    file_name, depth, x, y = test_sample\n",
    "    sign = np.sign(depth.iloc[-1]) ## assume all are depths are in same sign\n",
    "    yhat = clf.predict(x)\n",
    "    yhat = smooth(list(yhat), config['window_size'])\n",
    "    mapping = config['mapping']\n",
    "    output_path = config['output_path']\n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "    np.savetxt(os.path.join(output_path, 'prediction_{}'.format(\n",
    "        file_name)), np.array([depth, yhat, y]).T, fmt=\"%s\", delimiter=',',\n",
    "        header=','.join([config['depth_name'], 'predicted', 'true']))\n",
    "    true = y.map(mapping)\n",
    "    pred = pd.Series(yhat).map(mapping)\n",
    "    x1 = np.zeros_like(true)\n",
    "    x2 = np.ones_like(pred)\n",
    "    t1 = pred\n",
    "    t2 = true\n",
    "    t = np.append(t1, t2)\n",
    "    x = np.append(x1, x2)\n",
    "    y = np.append(depth, depth)\n",
    "    fig, ax1 = plt.subplots(figsize=(2, 8))\n",
    "    plt.title(file_name)\n",
    "    tick = np.arange(0, sign*depth.shape[0]/10, (depth[1]-depth[0])*100)\n",
    "    plt.xticks([0, 1],[\"Predicted\",\"Real\"])\n",
    "    \n",
    "    plt.yticks(tick)\n",
    "    plt.ylabel(config['depth_name'])\n",
    "    cmap = plt.get_cmap('viridis', len(mapping))\n",
    "    cax = ax1.scatter(x, y, c=t, s=999, marker='s', cmap=cmap)\n",
    "    cbar = fig.colorbar(cax, ticks=list(mapping.values()))\n",
    "    cbar.ax.set_yticklabels(list(mapping.keys()))\n",
    "    plt.savefig(os.path.join(output_path, '{}.png'.format(file_name)), bbox_inches = \"tight\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hash Map config \n",
    "\n",
    "config = {'train_path': './train.csv',\n",
    "          'test_path': './testing',\n",
    "          'output_path': './output',\n",
    "          'feature_names': ['qc', 'fs', 'u2','Level'],\n",
    "          'label_name': 'Label',\n",
    "          'depth_name': 'Level',\n",
    "          'test_size': 0.2,\n",
    "          'window_size': 8,\n",
    "          'mapping': {  \n",
    "                        'MD': 0,\n",
    "                        'DM':0,\n",
    "                        'ALL-c (pal)': 1,\n",
    "                        'ALL-c (unw)': 2,\n",
    "                        'ALL-c (int)': 3,\n",
    "                        'ALL-s': 4,\n",
    "                        'DS': 4,\n",
    "                        'GRADE V': 5\n",
    "                      }\n",
    "          }\n",
    "\n",
    "data = get_dataset(config)\n",
    "rf_param = {'n_estimators': 100, 'max_depth': 100}\n",
    "clf = train_rf(data, rf_param)\n",
    "\n",
    "####### Uncomment the below two lines for training on mlp ########\n",
    "#mlp_param = {'hidden_layer_sizes': (10,10,10,10,10,10,10), 'solver': 'adam', 'learning_rate_init': 0.01}\n",
    "#clf = train_mlp(data, mlp_param)\n",
    "#################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_samples = get_test_samples(config)\n",
    "for test_sample in test_samples:\n",
    "    print('processing {}'.format(test_sample[0]))\n",
    "    plot(clf, config, test_sample) ## w is the smoothing window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "331517b27b0753ea05225bd3f2ed83248f487609b4823144de1a05e78c21665f"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
